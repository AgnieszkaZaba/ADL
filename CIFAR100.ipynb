{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1kc5MFnm-rx",
        "colab_type": "text"
      },
      "source": [
        "# Classification CIFAR100\n",
        "Project 1 (Applied Deep Learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP721GfA0TfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2, l1\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VzM95-46L3i",
        "colab_type": "text"
      },
      "source": [
        "Download images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_YakiEK1gnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThETsailAVLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "#Augmentation of data\n",
        "image_gen_train = ImageDataGenerator(\n",
        "                    rotation_range=5,\n",
        "                    width_shift_range=.15,\n",
        "                    horizontal_flip=True\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6bezGot_joA",
        "colab_type": "code",
        "outputId": "0736fd17-d0e8-48a8-9a65-fe5623b14d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "#@title Default title text\n",
        "\n",
        "model = models.Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape=(32, 32 ,3), \n",
        "           kernel_regularizer=l2(l=0.0005)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(l=0.0005)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(l=0.0005)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((3,3)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(l=0.0005)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(l=0.0005)),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(100)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 30, 30, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 1, 1, 64)          256       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               6500      \n",
            "=================================================================\n",
            "Total params: 137,828\n",
            "Trainable params: 137,252\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz-PYz0OdqEQ",
        "colab_type": "code",
        "outputId": "d524b325-0f00-4461-ed52-607691cede52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels,  \n",
        "                    batch_size=batch_size, epochs=100, \n",
        "                    steps_per_epoch= len(train_images)/batch_size,\n",
        "                    validation_data=(test_images, test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 4.0633 - accuracy: 0.1038 - val_loss: 3.6549 - val_accuracy: 0.1594\n",
            "Epoch 2/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.5170 - accuracy: 0.1893 - val_loss: 3.2732 - val_accuracy: 0.2329\n",
            "Epoch 3/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.2528 - accuracy: 0.2387 - val_loss: 3.1060 - val_accuracy: 0.2792\n",
            "Epoch 4/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.1204 - accuracy: 0.2688 - val_loss: 2.9752 - val_accuracy: 0.2987\n",
            "Epoch 5/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.0404 - accuracy: 0.2885 - val_loss: 2.8126 - val_accuracy: 0.3468\n",
            "Epoch 6/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.9693 - accuracy: 0.3035 - val_loss: 2.7392 - val_accuracy: 0.3593\n",
            "Epoch 7/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.9243 - accuracy: 0.3166 - val_loss: 2.7220 - val_accuracy: 0.3591\n",
            "Epoch 8/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8886 - accuracy: 0.3244 - val_loss: 2.7292 - val_accuracy: 0.3608\n",
            "Epoch 9/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8593 - accuracy: 0.3331 - val_loss: 2.9929 - val_accuracy: 0.3046\n",
            "Epoch 10/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8409 - accuracy: 0.3380 - val_loss: 2.9806 - val_accuracy: 0.3127\n",
            "Epoch 11/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8100 - accuracy: 0.3446 - val_loss: 2.7510 - val_accuracy: 0.3556\n",
            "Epoch 12/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7967 - accuracy: 0.3471 - val_loss: 2.6752 - val_accuracy: 0.3786\n",
            "Epoch 13/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7827 - accuracy: 0.3535 - val_loss: 2.9832 - val_accuracy: 0.3160\n",
            "Epoch 14/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7651 - accuracy: 0.3583 - val_loss: 2.6594 - val_accuracy: 0.3780\n",
            "Epoch 15/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7522 - accuracy: 0.3613 - val_loss: 2.5868 - val_accuracy: 0.3949\n",
            "Epoch 16/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7423 - accuracy: 0.3617 - val_loss: 2.6154 - val_accuracy: 0.3912\n",
            "Epoch 17/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7278 - accuracy: 0.3679 - val_loss: 2.5529 - val_accuracy: 0.4031\n",
            "Epoch 18/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7333 - accuracy: 0.3652 - val_loss: 2.5928 - val_accuracy: 0.3978\n",
            "Epoch 19/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7210 - accuracy: 0.3680 - val_loss: 2.6433 - val_accuracy: 0.3876\n",
            "Epoch 20/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7173 - accuracy: 0.3679 - val_loss: 2.6243 - val_accuracy: 0.3860\n",
            "Epoch 21/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7038 - accuracy: 0.3699 - val_loss: 2.5742 - val_accuracy: 0.4040\n",
            "Epoch 22/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6991 - accuracy: 0.3751 - val_loss: 2.5158 - val_accuracy: 0.4106\n",
            "Epoch 23/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6886 - accuracy: 0.3747 - val_loss: 2.4906 - val_accuracy: 0.4213\n",
            "Epoch 24/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6908 - accuracy: 0.3744 - val_loss: 2.6823 - val_accuracy: 0.3836\n",
            "Epoch 25/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6853 - accuracy: 0.3760 - val_loss: 2.5799 - val_accuracy: 0.4004\n",
            "Epoch 26/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6795 - accuracy: 0.3773 - val_loss: 2.4687 - val_accuracy: 0.4252\n",
            "Epoch 27/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6800 - accuracy: 0.3769 - val_loss: 2.4558 - val_accuracy: 0.4255\n",
            "Epoch 28/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6643 - accuracy: 0.3824 - val_loss: 2.8308 - val_accuracy: 0.3541\n",
            "Epoch 29/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6656 - accuracy: 0.3824 - val_loss: 2.5195 - val_accuracy: 0.4128\n",
            "Epoch 30/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6581 - accuracy: 0.3834 - val_loss: 2.5219 - val_accuracy: 0.4128\n",
            "Epoch 31/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6508 - accuracy: 0.3838 - val_loss: 2.6139 - val_accuracy: 0.3940\n",
            "Epoch 32/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6524 - accuracy: 0.3862 - val_loss: 2.6360 - val_accuracy: 0.3926\n",
            "Epoch 33/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6474 - accuracy: 0.3872 - val_loss: 2.5063 - val_accuracy: 0.4169\n",
            "Epoch 34/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6427 - accuracy: 0.3907 - val_loss: 2.4860 - val_accuracy: 0.4234\n",
            "Epoch 35/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6423 - accuracy: 0.3848 - val_loss: 2.6564 - val_accuracy: 0.3916\n",
            "Epoch 36/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6356 - accuracy: 0.3879 - val_loss: 2.5068 - val_accuracy: 0.4217\n",
            "Epoch 37/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6313 - accuracy: 0.3895 - val_loss: 2.4732 - val_accuracy: 0.4251\n",
            "Epoch 38/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6314 - accuracy: 0.3904 - val_loss: 2.4595 - val_accuracy: 0.4299\n",
            "Epoch 39/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6278 - accuracy: 0.3916 - val_loss: 2.4527 - val_accuracy: 0.4280\n",
            "Epoch 40/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6246 - accuracy: 0.3936 - val_loss: 2.4255 - val_accuracy: 0.4338\n",
            "Epoch 41/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6217 - accuracy: 0.3910 - val_loss: 2.5239 - val_accuracy: 0.4103\n",
            "Epoch 42/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6287 - accuracy: 0.3915 - val_loss: 2.5056 - val_accuracy: 0.4111\n",
            "Epoch 43/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6130 - accuracy: 0.3958 - val_loss: 2.4236 - val_accuracy: 0.4401\n",
            "Epoch 44/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6168 - accuracy: 0.3954 - val_loss: 2.4564 - val_accuracy: 0.4281\n",
            "Epoch 45/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6123 - accuracy: 0.3961 - val_loss: 2.4177 - val_accuracy: 0.4375\n",
            "Epoch 46/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6127 - accuracy: 0.3974 - val_loss: 2.4174 - val_accuracy: 0.4413\n",
            "Epoch 47/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6097 - accuracy: 0.3961 - val_loss: 2.6353 - val_accuracy: 0.3923\n",
            "Epoch 48/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6110 - accuracy: 0.3952 - val_loss: 2.6338 - val_accuracy: 0.3879\n",
            "Epoch 49/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6114 - accuracy: 0.3943 - val_loss: 2.5297 - val_accuracy: 0.4076\n",
            "Epoch 50/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6083 - accuracy: 0.3980 - val_loss: 2.4228 - val_accuracy: 0.4348\n",
            "Epoch 51/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6058 - accuracy: 0.3972 - val_loss: 2.4521 - val_accuracy: 0.4297\n",
            "Epoch 52/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6014 - accuracy: 0.3980 - val_loss: 2.3661 - val_accuracy: 0.4523\n",
            "Epoch 53/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5963 - accuracy: 0.4001 - val_loss: 2.5330 - val_accuracy: 0.4182\n",
            "Epoch 54/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5951 - accuracy: 0.4013 - val_loss: 2.4528 - val_accuracy: 0.4295\n",
            "Epoch 55/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6038 - accuracy: 0.3958 - val_loss: 2.4335 - val_accuracy: 0.4366\n",
            "Epoch 56/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.6011 - accuracy: 0.3997 - val_loss: 2.4762 - val_accuracy: 0.4221\n",
            "Epoch 57/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5990 - accuracy: 0.3988 - val_loss: 2.4780 - val_accuracy: 0.4272\n",
            "Epoch 58/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5985 - accuracy: 0.3978 - val_loss: 2.6044 - val_accuracy: 0.3947\n",
            "Epoch 59/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5985 - accuracy: 0.3979 - val_loss: 2.9395 - val_accuracy: 0.3387\n",
            "Epoch 60/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5973 - accuracy: 0.3987 - val_loss: 2.4511 - val_accuracy: 0.4352\n",
            "Epoch 61/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5855 - accuracy: 0.4030 - val_loss: 2.5134 - val_accuracy: 0.4196\n",
            "Epoch 62/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5933 - accuracy: 0.4008 - val_loss: 2.4079 - val_accuracy: 0.4355\n",
            "Epoch 63/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5880 - accuracy: 0.4008 - val_loss: 2.4496 - val_accuracy: 0.4349\n",
            "Epoch 64/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5897 - accuracy: 0.4001 - val_loss: 2.4921 - val_accuracy: 0.4204\n",
            "Epoch 65/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5805 - accuracy: 0.4040 - val_loss: 2.4261 - val_accuracy: 0.4425\n",
            "Epoch 66/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5889 - accuracy: 0.4019 - val_loss: 2.6762 - val_accuracy: 0.3889\n",
            "Epoch 67/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5835 - accuracy: 0.3994 - val_loss: 2.5013 - val_accuracy: 0.4205\n",
            "Epoch 68/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5890 - accuracy: 0.4006 - val_loss: 2.5369 - val_accuracy: 0.4102\n",
            "Epoch 69/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5780 - accuracy: 0.4074 - val_loss: 2.4099 - val_accuracy: 0.4447\n",
            "Epoch 70/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5878 - accuracy: 0.4019 - val_loss: 2.4026 - val_accuracy: 0.4442\n",
            "Epoch 71/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5899 - accuracy: 0.4008 - val_loss: 2.4477 - val_accuracy: 0.4320\n",
            "Epoch 72/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5761 - accuracy: 0.4034 - val_loss: 2.6728 - val_accuracy: 0.3839\n",
            "Epoch 73/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5703 - accuracy: 0.4041 - val_loss: 2.4288 - val_accuracy: 0.4425\n",
            "Epoch 74/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5847 - accuracy: 0.4008 - val_loss: 2.4457 - val_accuracy: 0.4267\n",
            "Epoch 75/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5736 - accuracy: 0.4057 - val_loss: 2.3961 - val_accuracy: 0.4518\n",
            "Epoch 76/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5737 - accuracy: 0.4070 - val_loss: 2.3744 - val_accuracy: 0.4487\n",
            "Epoch 77/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5770 - accuracy: 0.4062 - val_loss: 2.3565 - val_accuracy: 0.4501\n",
            "Epoch 78/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5789 - accuracy: 0.4034 - val_loss: 2.3747 - val_accuracy: 0.4539\n",
            "Epoch 79/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5662 - accuracy: 0.4082 - val_loss: 2.7000 - val_accuracy: 0.3803\n",
            "Epoch 80/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5725 - accuracy: 0.4053 - val_loss: 2.5454 - val_accuracy: 0.4073\n",
            "Epoch 81/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5693 - accuracy: 0.4059 - val_loss: 2.3590 - val_accuracy: 0.4533\n",
            "Epoch 82/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5650 - accuracy: 0.4075 - val_loss: 2.4968 - val_accuracy: 0.4207\n",
            "Epoch 83/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5633 - accuracy: 0.4097 - val_loss: 2.4207 - val_accuracy: 0.4340\n",
            "Epoch 84/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5628 - accuracy: 0.4080 - val_loss: 2.3595 - val_accuracy: 0.4566\n",
            "Epoch 85/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5620 - accuracy: 0.4053 - val_loss: 2.8286 - val_accuracy: 0.3678\n",
            "Epoch 86/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5656 - accuracy: 0.4062 - val_loss: 2.4121 - val_accuracy: 0.4473\n",
            "Epoch 87/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5655 - accuracy: 0.4077 - val_loss: 2.4350 - val_accuracy: 0.4325\n",
            "Epoch 88/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5609 - accuracy: 0.4076 - val_loss: 2.4062 - val_accuracy: 0.4450\n",
            "Epoch 89/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5684 - accuracy: 0.4083 - val_loss: 2.3547 - val_accuracy: 0.4624\n",
            "Epoch 90/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5584 - accuracy: 0.4093 - val_loss: 2.4129 - val_accuracy: 0.4458\n",
            "Epoch 91/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5691 - accuracy: 0.4067 - val_loss: 2.4504 - val_accuracy: 0.4410\n",
            "Epoch 92/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5627 - accuracy: 0.4056 - val_loss: 2.3302 - val_accuracy: 0.4622\n",
            "Epoch 93/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5651 - accuracy: 0.4086 - val_loss: 2.4022 - val_accuracy: 0.4477\n",
            "Epoch 94/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5656 - accuracy: 0.4075 - val_loss: 2.3586 - val_accuracy: 0.4591\n",
            "Epoch 95/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5559 - accuracy: 0.4098 - val_loss: 2.3018 - val_accuracy: 0.4681\n",
            "Epoch 96/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5589 - accuracy: 0.4080 - val_loss: 2.3632 - val_accuracy: 0.4557\n",
            "Epoch 97/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5619 - accuracy: 0.4084 - val_loss: 2.3234 - val_accuracy: 0.4634\n",
            "Epoch 98/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5586 - accuracy: 0.4103 - val_loss: 2.3510 - val_accuracy: 0.4629\n",
            "Epoch 99/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5616 - accuracy: 0.4096 - val_loss: 2.5469 - val_accuracy: 0.4100\n",
            "Epoch 100/100\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.5710 - accuracy: 0.4081 - val_loss: 2.4184 - val_accuracy: 0.4400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic40n15c__Om",
        "colab_type": "code",
        "outputId": "ef26c027-c230-483e-97aa-1ef479480673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Uczenie z augmentacjÄ…\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels,  \n",
        "                    batch_size=batch_size, epochs=15, \n",
        "                    steps_per_epoch= len(train_images)/batch_size,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "history = model.fit(image_gen_train.flow(train_images, train_labels, shuffle=True),  \n",
        "                    batch_size=batch_size, initial_epoch=15, epochs=100, \n",
        "                    steps_per_epoch= len(train_images)/batch_size,\n",
        "                    validation_data=(test_images, test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 4.1091 - accuracy: 0.0920 - val_loss: 3.7701 - val_accuracy: 0.1448\n",
            "Epoch 2/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.5804 - accuracy: 0.1770 - val_loss: 3.4205 - val_accuracy: 0.2122\n",
            "Epoch 3/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.3180 - accuracy: 0.2245 - val_loss: 3.0229 - val_accuracy: 0.2929\n",
            "Epoch 4/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.1421 - accuracy: 0.2600 - val_loss: 3.0696 - val_accuracy: 0.2811\n",
            "Epoch 5/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 3.0453 - accuracy: 0.2859 - val_loss: 2.9803 - val_accuracy: 0.2969\n",
            "Epoch 6/15\n",
            "1563/1562 [==============================] - 12s 7ms/step - loss: 2.9771 - accuracy: 0.3037 - val_loss: 2.8922 - val_accuracy: 0.3164\n",
            "Epoch 7/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.9223 - accuracy: 0.3175 - val_loss: 2.7132 - val_accuracy: 0.3590\n",
            "Epoch 8/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8858 - accuracy: 0.3253 - val_loss: 2.8477 - val_accuracy: 0.3395\n",
            "Epoch 9/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8555 - accuracy: 0.3345 - val_loss: 2.6655 - val_accuracy: 0.3664\n",
            "Epoch 10/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8360 - accuracy: 0.3411 - val_loss: 2.6996 - val_accuracy: 0.3661\n",
            "Epoch 11/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.8139 - accuracy: 0.3460 - val_loss: 2.6012 - val_accuracy: 0.3972\n",
            "Epoch 12/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7975 - accuracy: 0.3491 - val_loss: 2.6102 - val_accuracy: 0.3912\n",
            "Epoch 13/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7812 - accuracy: 0.3529 - val_loss: 2.6209 - val_accuracy: 0.3868\n",
            "Epoch 14/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7667 - accuracy: 0.3600 - val_loss: 2.5183 - val_accuracy: 0.4093\n",
            "Epoch 15/15\n",
            "1563/1562 [==============================] - 11s 7ms/step - loss: 2.7539 - accuracy: 0.3601 - val_loss: 2.7832 - val_accuracy: 0.3543\n",
            "Epoch 16/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 2.9352 - accuracy: 0.3207 - val_loss: 2.6038 - val_accuracy: 0.3961\n",
            "Epoch 17/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 2.9023 - accuracy: 0.3296 - val_loss: 2.5354 - val_accuracy: 0.4092\n",
            "Epoch 18/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 2.8988 - accuracy: 0.3322 - val_loss: 2.5751 - val_accuracy: 0.3926\n",
            "Epoch 19/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8849 - accuracy: 0.3331 - val_loss: 2.5556 - val_accuracy: 0.4042\n",
            "Epoch 20/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8791 - accuracy: 0.3338 - val_loss: 2.5184 - val_accuracy: 0.4143\n",
            "Epoch 21/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 2.8661 - accuracy: 0.3350 - val_loss: 2.5670 - val_accuracy: 0.4007\n",
            "Epoch 22/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8676 - accuracy: 0.3334 - val_loss: 2.5889 - val_accuracy: 0.3953\n",
            "Epoch 23/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8580 - accuracy: 0.3405 - val_loss: 2.5358 - val_accuracy: 0.4075\n",
            "Epoch 24/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8576 - accuracy: 0.3384 - val_loss: 2.5306 - val_accuracy: 0.4134\n",
            "Epoch 25/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8414 - accuracy: 0.3411 - val_loss: 2.5621 - val_accuracy: 0.4028\n",
            "Epoch 26/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8450 - accuracy: 0.3426 - val_loss: 2.5308 - val_accuracy: 0.4118\n",
            "Epoch 27/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8377 - accuracy: 0.3417 - val_loss: 2.5340 - val_accuracy: 0.4073\n",
            "Epoch 28/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 2.8326 - accuracy: 0.3431 - val_loss: 2.5216 - val_accuracy: 0.4140\n",
            "Epoch 29/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8229 - accuracy: 0.3487 - val_loss: 2.4541 - val_accuracy: 0.4278\n",
            "Epoch 30/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8183 - accuracy: 0.3460 - val_loss: 2.4817 - val_accuracy: 0.4192\n",
            "Epoch 31/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8207 - accuracy: 0.3490 - val_loss: 2.5443 - val_accuracy: 0.4025\n",
            "Epoch 32/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8152 - accuracy: 0.3487 - val_loss: 2.5896 - val_accuracy: 0.4016\n",
            "Epoch 33/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8148 - accuracy: 0.3510 - val_loss: 2.4681 - val_accuracy: 0.4219\n",
            "Epoch 34/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8130 - accuracy: 0.3507 - val_loss: 2.4261 - val_accuracy: 0.4348\n",
            "Epoch 35/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8010 - accuracy: 0.3501 - val_loss: 2.5084 - val_accuracy: 0.4157\n",
            "Epoch 36/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7928 - accuracy: 0.3536 - val_loss: 2.4486 - val_accuracy: 0.4305\n",
            "Epoch 37/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.8000 - accuracy: 0.3510 - val_loss: 2.5202 - val_accuracy: 0.4168\n",
            "Epoch 38/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7896 - accuracy: 0.3549 - val_loss: 2.4696 - val_accuracy: 0.4273\n",
            "Epoch 39/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7946 - accuracy: 0.3539 - val_loss: 2.4664 - val_accuracy: 0.4302\n",
            "Epoch 40/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7898 - accuracy: 0.3534 - val_loss: 2.4441 - val_accuracy: 0.4323\n",
            "Epoch 41/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7947 - accuracy: 0.3532 - val_loss: 2.5039 - val_accuracy: 0.4124\n",
            "Epoch 42/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7879 - accuracy: 0.3561 - val_loss: 2.5745 - val_accuracy: 0.4015\n",
            "Epoch 43/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7795 - accuracy: 0.3555 - val_loss: 2.4517 - val_accuracy: 0.4294\n",
            "Epoch 44/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7806 - accuracy: 0.3594 - val_loss: 2.4309 - val_accuracy: 0.4308\n",
            "Epoch 45/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7870 - accuracy: 0.3549 - val_loss: 2.4422 - val_accuracy: 0.4318\n",
            "Epoch 46/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7750 - accuracy: 0.3570 - val_loss: 2.4706 - val_accuracy: 0.4248\n",
            "Epoch 47/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7687 - accuracy: 0.3578 - val_loss: 2.5083 - val_accuracy: 0.4171\n",
            "Epoch 48/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7771 - accuracy: 0.3553 - val_loss: 2.4593 - val_accuracy: 0.4263\n",
            "Epoch 49/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7750 - accuracy: 0.3594 - val_loss: 2.4384 - val_accuracy: 0.4311\n",
            "Epoch 50/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7736 - accuracy: 0.3596 - val_loss: 2.4903 - val_accuracy: 0.4200\n",
            "Epoch 51/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7688 - accuracy: 0.3596 - val_loss: 2.5261 - val_accuracy: 0.4096\n",
            "Epoch 52/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7610 - accuracy: 0.3587 - val_loss: 2.5774 - val_accuracy: 0.3967\n",
            "Epoch 53/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7689 - accuracy: 0.3607 - val_loss: 2.5365 - val_accuracy: 0.4140\n",
            "Epoch 54/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7594 - accuracy: 0.3614 - val_loss: 2.5246 - val_accuracy: 0.4180\n",
            "Epoch 55/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7607 - accuracy: 0.3628 - val_loss: 2.5788 - val_accuracy: 0.4111\n",
            "Epoch 56/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7552 - accuracy: 0.3652 - val_loss: 2.4462 - val_accuracy: 0.4330\n",
            "Epoch 57/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7571 - accuracy: 0.3647 - val_loss: 2.4966 - val_accuracy: 0.4211\n",
            "Epoch 58/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7545 - accuracy: 0.3616 - val_loss: 2.4424 - val_accuracy: 0.4293\n",
            "Epoch 59/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7555 - accuracy: 0.3636 - val_loss: 2.4468 - val_accuracy: 0.4277\n",
            "Epoch 60/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7591 - accuracy: 0.3639 - val_loss: 2.4403 - val_accuracy: 0.4365\n",
            "Epoch 61/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7510 - accuracy: 0.3636 - val_loss: 2.4197 - val_accuracy: 0.4345\n",
            "Epoch 62/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7584 - accuracy: 0.3638 - val_loss: 2.4429 - val_accuracy: 0.4355\n",
            "Epoch 63/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7399 - accuracy: 0.3640 - val_loss: 2.5511 - val_accuracy: 0.4142\n",
            "Epoch 64/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7449 - accuracy: 0.3652 - val_loss: 2.3918 - val_accuracy: 0.4449\n",
            "Epoch 65/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7553 - accuracy: 0.3640 - val_loss: 2.3407 - val_accuracy: 0.4608\n",
            "Epoch 66/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7519 - accuracy: 0.3625 - val_loss: 2.4612 - val_accuracy: 0.4361\n",
            "Epoch 67/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7492 - accuracy: 0.3644 - val_loss: 2.4336 - val_accuracy: 0.4413\n",
            "Epoch 68/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7436 - accuracy: 0.3675 - val_loss: 2.3818 - val_accuracy: 0.4450\n",
            "Epoch 69/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7528 - accuracy: 0.3652 - val_loss: 2.4196 - val_accuracy: 0.4383\n",
            "Epoch 70/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7426 - accuracy: 0.3655 - val_loss: 2.4243 - val_accuracy: 0.4348\n",
            "Epoch 71/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7427 - accuracy: 0.3666 - val_loss: 2.4728 - val_accuracy: 0.4277\n",
            "Epoch 72/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7411 - accuracy: 0.3680 - val_loss: 2.4255 - val_accuracy: 0.4407\n",
            "Epoch 73/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7414 - accuracy: 0.3655 - val_loss: 2.3741 - val_accuracy: 0.4455\n",
            "Epoch 74/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7355 - accuracy: 0.3687 - val_loss: 2.4806 - val_accuracy: 0.4232\n",
            "Epoch 75/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7336 - accuracy: 0.3681 - val_loss: 2.3754 - val_accuracy: 0.4483\n",
            "Epoch 76/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7320 - accuracy: 0.3678 - val_loss: 2.4404 - val_accuracy: 0.4339\n",
            "Epoch 77/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7335 - accuracy: 0.3694 - val_loss: 2.3806 - val_accuracy: 0.4453\n",
            "Epoch 78/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7397 - accuracy: 0.3680 - val_loss: 2.5084 - val_accuracy: 0.4175\n",
            "Epoch 79/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7389 - accuracy: 0.3691 - val_loss: 2.4826 - val_accuracy: 0.4264\n",
            "Epoch 80/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7363 - accuracy: 0.3684 - val_loss: 2.4623 - val_accuracy: 0.4358\n",
            "Epoch 81/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7364 - accuracy: 0.3689 - val_loss: 2.5954 - val_accuracy: 0.4080\n",
            "Epoch 82/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7324 - accuracy: 0.3681 - val_loss: 2.3878 - val_accuracy: 0.4504\n",
            "Epoch 83/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7319 - accuracy: 0.3686 - val_loss: 2.4497 - val_accuracy: 0.4339\n",
            "Epoch 84/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7340 - accuracy: 0.3681 - val_loss: 2.4684 - val_accuracy: 0.4305\n",
            "Epoch 85/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7341 - accuracy: 0.3710 - val_loss: 2.4088 - val_accuracy: 0.4421\n",
            "Epoch 86/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7324 - accuracy: 0.3709 - val_loss: 2.3643 - val_accuracy: 0.4498\n",
            "Epoch 87/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7338 - accuracy: 0.3701 - val_loss: 2.4792 - val_accuracy: 0.4253\n",
            "Epoch 88/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7321 - accuracy: 0.3684 - val_loss: 2.4674 - val_accuracy: 0.4229\n",
            "Epoch 89/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7313 - accuracy: 0.3716 - val_loss: 2.4570 - val_accuracy: 0.4234\n",
            "Epoch 90/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7224 - accuracy: 0.3720 - val_loss: 2.4629 - val_accuracy: 0.4299\n",
            "Epoch 91/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7345 - accuracy: 0.3685 - val_loss: 2.4365 - val_accuracy: 0.4406\n",
            "Epoch 92/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7361 - accuracy: 0.3685 - val_loss: 2.4062 - val_accuracy: 0.4457\n",
            "Epoch 93/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7328 - accuracy: 0.3689 - val_loss: 2.5079 - val_accuracy: 0.4265\n",
            "Epoch 94/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7282 - accuracy: 0.3713 - val_loss: 2.4041 - val_accuracy: 0.4426\n",
            "Epoch 95/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7244 - accuracy: 0.3725 - val_loss: 2.4184 - val_accuracy: 0.4467\n",
            "Epoch 96/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7276 - accuracy: 0.3702 - val_loss: 2.3897 - val_accuracy: 0.4553\n",
            "Epoch 97/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7263 - accuracy: 0.3712 - val_loss: 2.4092 - val_accuracy: 0.4412\n",
            "Epoch 98/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7236 - accuracy: 0.3730 - val_loss: 2.3990 - val_accuracy: 0.4435\n",
            "Epoch 99/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7212 - accuracy: 0.3728 - val_loss: 2.4359 - val_accuracy: 0.4373\n",
            "Epoch 100/100\n",
            "1563/1562 [==============================] - 31s 20ms/step - loss: 2.7224 - accuracy: 0.3713 - val_loss: 2.4548 - val_accuracy: 0.4330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhRh0NXT1ITg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn0R8DOiBPyQ",
        "colab_type": "code",
        "outputId": "9b186610-16ea-4a1b-bf70-8febdb0c2d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.2, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 2.4184 - accuracy: 0.4400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0aAURtmCqIP",
        "colab_type": "code",
        "outputId": "36ef2852-1146-4e5e-e90e-725e6dacaf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_acc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4399999976158142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZfxKEVcEK0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}